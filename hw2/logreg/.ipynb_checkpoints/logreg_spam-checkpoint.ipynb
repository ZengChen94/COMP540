{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311363] [[ -2.74146423e-02  -2.25297597e-01   1.21840933e-01   2.29362879e+00\n",
      "    2.70425715e-01   2.32851163e-01   9.28595395e-01   2.95200236e-01\n",
      "    1.62205936e-01   6.78260362e-02  -8.32604386e-02  -1.60373354e-01\n",
      "   -4.72247682e-02   1.07677111e-02   1.87903360e-01   8.19771812e-01\n",
      "    5.09528973e-01   3.98711504e-02   2.67729695e-01   3.47047564e-01\n",
      "    2.60498923e-01   3.64605215e-01   7.25019578e-01   1.96728249e-01\n",
      "   -3.15395701e+00  -4.03133789e-01  -1.25451044e+01  -6.16580960e-02\n",
      "   -1.56114609e+00  -5.51429801e-02  -3.00815864e-02   4.07263543e-01\n",
      "   -3.68156446e-01  -1.43611787e+00  -5.87180606e-01   4.44294891e-01\n",
      "    4.23159462e-02  -1.56897094e-01  -4.55330838e-01  -1.02250289e-01\n",
      "   -3.54273295e+00  -1.72944487e+00  -4.37529300e-01  -1.05999941e+00\n",
      "   -9.18599328e-01  -1.75490328e+00  -1.67475856e-01  -9.56875266e-01\n",
      "   -3.65653149e-01  -1.36535510e-01  -6.58692488e-02   2.06714030e-01\n",
      "    1.70694385e+00   1.21460313e+00  -3.35269880e-01   1.56141411e+00\n",
      "    3.68775701e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.90069276] [[-0.52474803 -0.26161479 -0.12625061  0.98504676  1.26918843  0.9929532\n",
      "   3.11335249  1.49782092  0.32474953  0.41274444 -0.61223611 -0.47700555\n",
      "  -0.84942799  0.4188976   0.76808199  1.58787977  1.54892036 -0.06332927\n",
      "   0.40987111  0.77733549  0.51211957  0.46134792  2.14267469  1.48610973\n",
      "  -3.68708583 -0.45731188 -9.89801644  0.18444694 -2.17393056  0.03824204\n",
      "  -0.04447696 -0.44328482 -1.02179179 -0.89940267 -1.77915287  1.64137307\n",
      "  -0.7863304  -0.4887348  -1.35293841 -0.42225198 -3.29849924 -3.46987265\n",
      "  -3.14913037 -2.89137075 -1.38874523 -3.21214123 -1.77933302 -4.18328883\n",
      "  -2.3059683  -0.91988062 -1.04844476  2.08771702  5.7767944   1.09951613\n",
      "   0.83241189  0.08194502  0.53307471]]\n",
      "Accuracy on set aside test set for  logt  =  0.94140625\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-1.77220909] [[-0.27014719 -0.13652489 -0.44105032  0.19592905  1.09940104  0.28383013\n",
      "   2.39370368  0.89848648  0.26534245  0.43563214 -0.3972658  -0.428833\n",
      "  -1.07464569  0.3230411   0.66669314  1.58604183  1.10346005 -0.17358371\n",
      "   0.24915662  0.76718998  0.78417569  1.4247552   1.03882805  1.61862469\n",
      "  -2.93736184 -0.23318678 -5.85001871  1.26266051 -0.83078126 -0.06707888\n",
      "  -1.65514696 -1.71955723 -0.92717811  0.44738229 -0.73942315  0.51821007\n",
      "  -1.06391582  1.07668069 -0.98243026 -0.32996279 -2.96960893 -2.53985275\n",
      "  -1.21090782 -2.16548571 -0.85214134 -2.56732974  0.03486375 -2.02739786\n",
      "  -0.37388685  0.22126841 -0.21524011  1.27340608  1.59564385 -0.03239231\n",
      "  -0.04451539 -0.04451539 -0.04451539]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-11.96094546] [[ -5.33110616e-02  -2.02643219e-01   1.08790187e-01   2.85351096e+00\n",
      "    2.68840673e-01   2.59325341e-01   8.99571600e-01   2.98463541e-01\n",
      "    2.29292292e-01   6.95643211e-02  -6.89211681e-02  -1.54062018e-01\n",
      "   -3.30292077e-02   1.63529957e-02   1.62489107e-01   7.99200686e-01\n",
      "    5.36038436e-01   3.52554912e-02   2.69016680e-01   3.32511483e-01\n",
      "    2.54618912e-01   3.38199367e-01   6.94671511e-01   1.74920889e-01\n",
      "   -3.22256716e+00  -3.20169045e-01  -4.45461201e+01  -6.06845154e-02\n",
      "   -1.43493170e+00  -1.31272704e-02   1.76870339e-01   5.69721457e-01\n",
      "   -3.28841232e-01  -1.43346823e-01  -7.28530301e-01   4.34046852e-01\n",
      "    5.85667553e-02  -1.55420736e-01  -4.52562334e-01  -4.06342101e-02\n",
      "   -5.30918783e+00  -1.85678800e+00  -5.20690627e-01  -1.01240616e+00\n",
      "   -9.15985721e-01  -1.76687329e+00  -1.70158101e-01  -1.20442745e+00\n",
      "   -3.51794440e-01  -1.35870862e-01  -5.44238585e-02   1.98163329e-01\n",
      "    1.70997180e+00   1.09179506e+00   7.23127229e-02   2.58450653e+00\n",
      "    3.16411090e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.92578125\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-5.01335848] [[ -0.54525561  -0.18222595  -0.12550563   0.94899139   1.27000177\n",
      "    1.11001793   3.11654963   1.47934286   0.48101494   0.50023509\n",
      "   -0.60606384  -0.46554112  -0.90915627   0.47807259   0.60488982\n",
      "    1.58997263   1.71735212  -0.0905728    0.41441976   0.85146957\n",
      "    0.51318606   0.47102677   2.22398913   1.40718143  -3.8778599\n",
      "   -0.30219932 -18.38291185   0.19968081  -2.50375873   0.           0.45256253\n",
      "    0.          -0.90862058   0.          -2.00002619   1.69344796\n",
      "   -0.65256805  -0.42862048  -1.40113082  -0.11065744  -9.39110805\n",
      "   -4.03350056  -3.93053193  -3.209712    -1.4943745   -3.28398195\n",
      "   -2.39900007  -5.56914586  -2.44285105  -1.00586242  -0.76735095\n",
      "    2.09981255   6.62729018   1.12465428   0.79203271   0.06618701\n",
      "    0.58019264]]\n",
      "Accuracy on set aside test set for  logt  =  0.938802083333\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-0.44000459] [[-0.27354903 -0.120922   -0.43820124  0.13366115  1.10400544  0.29944638\n",
      "   2.42039344  0.90497719  0.267127    0.44609945 -0.41181684 -0.42706669\n",
      "  -1.09420153  0.31953612  0.66144843  1.59480531  1.13614306 -0.18192778\n",
      "   0.2434626   0.80267032  0.78772322  1.41366246  1.03793307  1.65676061\n",
      "  -3.01325335 -0.19529083 -6.22033511  1.30824272 -0.83099988 -0.04022672\n",
      "  -1.74022327 -1.90248571 -0.94471049  0.20433485 -0.72636572  0.52652331\n",
      "  -1.05121058  1.10869502 -0.9959416  -0.30729442 -4.06572299 -2.61268517\n",
      "  -1.25498287 -2.21913808 -0.86111778 -2.58717794  0.         -2.10757615\n",
      "  -0.38116186  0.2195019  -0.20761706  1.28243597  1.61432752 -0.02027649\n",
      "  -0.37667149 -0.22240342 -0.87174752]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
