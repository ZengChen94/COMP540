{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311363] [[ -2.74146423e-02  -2.25297597e-01   1.21840933e-01   2.29362879e+00\n",
      "    2.70425715e-01   2.32851163e-01   9.28595395e-01   2.95200236e-01\n",
      "    1.62205936e-01   6.78260362e-02  -8.32604386e-02  -1.60373354e-01\n",
      "   -4.72247682e-02   1.07677111e-02   1.87903360e-01   8.19771812e-01\n",
      "    5.09528973e-01   3.98711504e-02   2.67729695e-01   3.47047564e-01\n",
      "    2.60498923e-01   3.64605215e-01   7.25019578e-01   1.96728249e-01\n",
      "   -3.15395701e+00  -4.03133789e-01  -1.25451044e+01  -6.16580960e-02\n",
      "   -1.56114609e+00  -5.51429801e-02  -3.00815864e-02   4.07263543e-01\n",
      "   -3.68156446e-01  -1.43611787e+00  -5.87180606e-01   4.44294891e-01\n",
      "    4.23159462e-02  -1.56897094e-01  -4.55330838e-01  -1.02250289e-01\n",
      "   -3.54273295e+00  -1.72944487e+00  -4.37529300e-01  -1.05999941e+00\n",
      "   -9.18599328e-01  -1.75490328e+00  -1.67475856e-01  -9.56875266e-01\n",
      "   -3.65653149e-01  -1.36535510e-01  -6.58692488e-02   2.06714030e-01\n",
      "    1.70694385e+00   1.21460313e+00  -3.35269880e-01   1.56141411e+00\n",
      "    3.68775701e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60944667] [[-0.45145887 -0.28466502 -0.06327819  0.68295804  1.21053197  0.91504987\n",
      "   2.83046244  1.43677856  0.24145457  0.35775723 -0.38642638 -0.48142751\n",
      "  -0.69586861  0.37457025  0.64885478  1.5395627   1.38118339  0.07197747\n",
      "   0.37642217  0.63501926  0.52274838  0.38563703  2.00138627  1.50817467\n",
      "  -3.14060836 -0.66617179 -4.90648468 -0.03260466 -1.28886313 -0.15745822\n",
      "  -0.6389963  -0.30229058 -1.00990215 -0.42568565 -1.08721623  1.28432651\n",
      "  -0.90558978 -0.35285879 -1.12971405 -0.62589095 -1.40337046 -2.44123337\n",
      "  -1.55653325 -1.9477813  -1.13113514 -2.79991122 -0.7512231  -2.11601915\n",
      "  -1.68510766 -0.66773402 -0.69125555  2.06913245  4.21977733  0.7630898\n",
      "   0.70345803  0.17008574  0.43018819]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "best_lambda =  1.1\n",
      "Coefficients =  [-1.83742964] [[ -1.91463199e-01  -1.66872958e-01  -3.93802023e-01   2.39462779e-01\n",
      "    9.83292893e-01   1.75311414e-01   2.12183419e+00   7.92547596e-01\n",
      "    1.94566579e-01   3.34388296e-01  -2.90824615e-01  -4.20297341e-01\n",
      "   -9.06380381e-01   2.56299856e-01   5.15189474e-01   1.47014136e+00\n",
      "    8.76696476e-01  -8.32760956e-02   2.41264180e-01   5.01801273e-01\n",
      "    7.37046896e-01   1.15518007e+00   9.11195183e-01   1.36902984e+00\n",
      "   -2.35248856e+00  -4.17190306e-01  -3.79772643e+00   6.88337611e-01\n",
      "   -6.07237597e-01  -1.61622832e-01  -9.24671804e-01  -6.04558748e-01\n",
      "   -6.91161481e-01  -3.85638231e-02  -6.71440136e-01   3.52732370e-01\n",
      "   -1.05408408e+00   5.28551480e-01  -7.65306731e-01  -2.46067578e-01\n",
      "   -1.27643951e+00  -1.90613122e+00  -7.90184279e-01  -1.57619158e+00\n",
      "   -7.64312034e-01  -2.22366816e+00  -8.34144234e-02  -1.39371572e+00\n",
      "   -3.06993897e-01   2.00231957e-01  -1.70968577e-01   1.20762876e+00\n",
      "    1.45771409e+00   3.79908693e-02   5.31813313e-04   5.31813313e-04\n",
      "    5.31813313e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.927734375\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  4.6\n",
      "Coefficients =  [-1.58381002] [[-0.01058652 -0.158635    0.12269442  0.20853003  0.24912155  0.17682778\n",
      "   0.91092523  0.28986458  0.13946294  0.04856137 -0.02287558 -0.13987728\n",
      "  -0.0071229   0.00919877  0.15351539  0.75694037  0.46016297  0.07051028\n",
      "   0.25408878  0.19617054  0.24304966  0.34689526  0.72804025  0.23441873\n",
      "  -2.33630653 -0.3577559  -3.14343319 -0.01042851 -0.36891028  0.          0.\n",
      "   0.         -0.32767321  0.         -0.061866    0.24247026  0.\n",
      "  -0.11596452 -0.31084549 -0.04389515 -0.23985655 -0.79680104 -0.19023315\n",
      "  -0.56299327 -0.73349329 -1.178755   -0.08543114 -0.51228246 -0.25660443\n",
      "  -0.13383836 -0.05680331  0.21845799  1.64896809  0.22154996  0.\n",
      "   0.64843461  0.33270598]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-4.46314977] [[-0.34342647 -0.095663    0.          0.12934199  1.18454536  0.69060377\n",
      "   2.91324292  1.37685415  0.          0.29508452  0.         -0.48051265\n",
      "  -0.32793673  0.10737905  0.          1.49528469  1.34903577  0.\n",
      "   0.35493134  0.19667835  0.49446459  0.34756502  1.78469939  1.32951302\n",
      "  -3.4976826  -0.26975083 -7.49408826  0.         -0.41753072  0.          0.\n",
      "   0.         -0.79140897  0.         -0.2388065   0.8718892  -0.77444247\n",
      "   0.         -0.88295528  0.         -0.30398199 -2.3551678  -0.69466813\n",
      "  -1.66134196 -1.13787847 -2.98268781  0.         -1.90116163 -1.24494115\n",
      "  -0.30329311  0.          2.01464787  5.36624902  0.          0.63672028\n",
      "   0.20192552  0.38810004]]\n",
      "Accuracy on set aside test set for  logt  =  0.944010416667\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.60800978] [[ 0.          0.         -0.19365686  0.          0.8659248   0.\n",
      "   2.02970694  0.63307969  0.02655894  0.2126538   0.         -0.42130111\n",
      "  -0.68109493  0.          0.          1.31576288  0.76597753  0.\n",
      "   0.10631568  0.12268871  0.63592706  0.7303457   0.62169968  1.18378813\n",
      "  -2.42443856 -0.12552217 -3.73140211  0.          0.          0.          0.\n",
      "   0.         -0.28801622  0.         -0.21911365  0.         -1.01549005\n",
      "   0.         -0.40501088  0.         -0.11531228 -1.69458256 -0.03921286\n",
      "  -1.10998115 -0.68744455 -2.21957039  0.         -1.0255363  -0.12500369\n",
      "   0.07400932  0.          1.15082964  1.49994313  0.         -0.80158695\n",
      "  -0.02421813 -0.23236336]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
