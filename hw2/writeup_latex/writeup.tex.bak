%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage{graphicx}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize
\textsc{Rice University, Department of Computer Science} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Assignment 2, COMP 540 \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Chen Zeng(cz39), Zhihui Xie(zx18)} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{Gradient and Hessian of $NLL\left ( \theta  \right )$ for logistic regression}

\paragraph{\textbf{Answer1}}
Because of:
\begin{equation*}
g\left ( z \right )=\frac{1}{\left ( 1+e^{-z} \right )}
\end{equation*}
We can get:
\begin{equation*}
g\left ( z \right )\left ( 1+e^{-z} \right )=1
\end{equation*}
Take the derivation on both side of the z, then we can get:
\begin{equation*}
{g}'\left ( z \right )\left ( 1+e^{-z} \right )-g\left ( z \right )e^{-z}=0
\end{equation*}
Finally, after some basic transformation, we can get:
\begin{equation*}
\frac{\partial g\left ( z \right )}{\partial z}=g\left ( z \right )\left ( 1-g\left ( z \right ) \right )
\end{equation*}
Therefore, the conclusion is proved.

\paragraph{\textbf{Answer2}}
As we know:
\begin{equation*}
NLL\left ( \theta  \right )=\frac{1}{2}\sum_{i=1}^{m}\left ( y^{\left ( i \right )}-\theta ^{T}x^{\left ( i \right )} \right )^{2}
\end{equation*}
Take the derivation on it of the parameter $\theta_{j}$, we can get:
\begin{equation*}
\frac{\partial NLL\left ( \theta  \right ) }{\partial \theta _{j}}=x_{j}^{\left ( i \right )}\sum_{i=1}^{m}\left ( \sum_{j=1}^{d} \left (x_{j}^{\left ( i \right )}\theta _{j}\right) -y^{\left ( i \right )} \right )
\end{equation*}
Therefore, take the derivation on $NLL\left ( \theta  \right )$ of vector $\theta$, we can get:
\begin{equation*}
\frac{\partial NLL\left ( \theta  \right ) }{\partial \theta }=\sum_{i=1}^{m}\left ( \theta ^{T}x^{\left ( i \right )} -y^{\left ( i \right )} \right )x^{\left ( i \right )}
\end{equation*}
It's the same as another format:
\begin{equation*}
\frac{\partial NLL\left ( \theta  \right ) }{\partial \theta }=\sum_{i=1}^{m}\left ( h_{\theta }\left ( x^{\left ( i \right )} \right ) -y^{\left ( i \right )} \right )x^{\left ( i \right )}
\end{equation*}
Therefore, the conclusion is proved.

\paragraph{\textbf{Answer3}}
Now we know that take the derivation on $NLL\left ( \theta  \right )$ of the parameter $\theta_{j}$, we can get:
\begin{equation*}
\frac{\partial NLL\left ( \theta  \right ) }{\partial \theta _{j}}=x_{j}^{\left ( i \right )}\sum_{i=1}^{m}\left ( \sum_{j=1}^{d} \left (x_{j}^{\left ( i \right )}\theta _{j}\right) -y^{\left ( i \right )} \right )
\end{equation*}
Then let's take the second derivative on $NLL\left ( \theta  \right )$ of the parameter $\theta_{j}$, we can get:
\begin{equation*}
\frac{\partial^2 NLL\left ( \theta  \right )}{\partial \theta _{j}^2}=\frac{\partial }{\partial \theta _{j}}\left ( x_{j}^{\left ( i \right )}\sum_{i=1}^{m}\left ( \sum_{j=1}^{d} \left (x_{j}^{\left ( i \right )}\theta _{j}\right) -y^{\left ( i \right )} \right ) \right )=m\left ( x_{j}^{\left ( i \right )} \right )^{2}
\end{equation*}
Therefore, take the second derivation on $NLL\left ( \theta  \right )$ of vector $\theta$, we can get:
\begin{equation*}
H=\frac{\partial^2 NLL\left ( \theta  \right )}{\partial \theta ^2}=m\sum_{j=1}^{d}\left ( x_{j}^{\left ( i \right )} \right )^{2}\geqslant 0
\end{equation*}
It proves that $H$ is positive definite.

\section{Properties of L2 regularized logistic regression}
\paragraph{\textbf{Answer1}}True. The solutions include batch gradient descent, stochastic gradient descent, closed form solution, etc.

\paragraph{\textbf{Answer2}}False. Ridge regularization drives $\theta$ components to zero but not to exactly zero.

\paragraph{\textbf{Answer3}}False. The coefficients $\theta_{j}$ won't become infinite because $J\left ( \theta  \right )$ is always a convex function even if $\lambda$ is 0

\paragraph{\textbf{Answer4}}True. As we increase $\lambda$, the second term of $\theta_{j}$ will increase too. We tend to minimize the loss function and the sigh before the first term is negative. Therefore, the first term will always increases.

\section{Implementing a k-nearest-neighbor classifier} Please help to refer to fold knn.

\section{Implementing logistic regression}

\end{document}

